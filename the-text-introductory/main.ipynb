{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c4f4ad",
   "metadata": {
    "id": "4831a35c"
   },
   "source": [
    "# The Text: Introductory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb17ce9b",
   "metadata": {
    "id": "be403152"
   },
   "source": [
    "### Installing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671781a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83344,
     "status": "ok",
     "timestamp": 1640182577233,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "0fd5a2d2",
    "outputId": "6d21cb80-ac76-4dc4-e55f-2a1ac4182a5b"
   },
   "outputs": [],
   "source": [
    "% pip install dateparser feedparser==6.0.8 requests==2.26.0 bs4==0.0.1 numpy==1.21.4 pandas==1.3.5 networkx==2.6.3 matplotlib==3.5.1 nltk==3.6.5 scikit-learn==1.0.1 tensorflow==2.7.0 spacy==3.2.1 langdetect deep_translator\n",
    "import nltk; nltk.download('stopwords'); nltk.download('punkt')\n",
    "!python -m spacy download en_core_web_lg\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da4fa0",
   "metadata": {
    "id": "HdIOZHpkd6va"
   },
   "source": [
    "### Connect Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be2a27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18104,
     "status": "ok",
     "timestamp": 1640182165418,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "_F_5hbbGd-Ik",
    "outputId": "8ea5f164-f1d1-4103-e1b7-26d3914a98f6"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d9443",
   "metadata": {
    "id": "FWGs3HBMd_Mo"
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1b1667",
   "metadata": {
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1640182177391,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "n0zZnEaeeAxj"
   },
   "outputs": [],
   "source": [
    "current_directory = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da5fb26",
   "metadata": {
    "id": "89d59d87"
   },
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790fd184",
   "metadata": {
    "executionInfo": {
     "elapsed": 355,
     "status": "ok",
     "timestamp": 1640183040436,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "ef48ec39"
   },
   "outputs": [],
   "source": [
    "from dateparser import parse as parse_date\n",
    "import feedparser\n",
    "import urllib\n",
    "import requests\n",
    "import re\n",
    "import copy\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from nltk import corpus, tokenize\n",
    "from sklearn import feature_extraction, metrics, model_selection, preprocessing, cluster\n",
    "import tensorflow as tf\n",
    "import spacy\n",
    "from string import punctuation\n",
    "from langdetect import detect\n",
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274cc27a",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1640182198603,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "20eff56d"
   },
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576ad863",
   "metadata": {
    "id": "853af0c3"
   },
   "source": [
    "### Scraper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd5a757",
   "metadata": {
    "executionInfo": {
     "elapsed": 936,
     "status": "ok",
     "timestamp": 1640182203309,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "444ab5d0"
   },
   "outputs": [],
   "source": [
    "class Scraper:\n",
    "    def __init__(self, language='en', country='MY'):\n",
    "        \"\"\"\n",
    "            :param str country: two string country code, example: 'MY', 'US'\n",
    "            :param str language: news language\n",
    "        \"\"\"\n",
    "        self.lang = language.lower()\n",
    "        self.country = country.upper()\n",
    "        self.BASE_URL = 'https://news.google.com/rss'\n",
    "\n",
    "    def __news_parser(self, text):\n",
    "        try:\n",
    "            bs4_html = BeautifulSoup(text, 'html.parser')\n",
    "            lis = bs4_html.find_all('li')\n",
    "            sub_articles = []\n",
    "            for li in lis:\n",
    "                try:\n",
    "                    sub_articles.append({'url': li.a['href'],\n",
    "                                         'title': li.a.text,\n",
    "                                         'publisher': li.font.text})\n",
    "                except:\n",
    "                    pass\n",
    "            return sub_articles\n",
    "        except:\n",
    "            return text\n",
    "\n",
    "    def __ceid(self):\n",
    "        return '?ceid={}:{}&hl={}&gl={}'.format(self.country, self.lang, self.lang, self.country)\n",
    "\n",
    "    def __add_sub_articles(self, entries):\n",
    "        for i, val in enumerate(entries):\n",
    "            if 'summary' in entries[i].keys():\n",
    "                entries[i]['sub_articles'] = self.__news_parser(entries[i]['summary'])\n",
    "            else:\n",
    "                entries[i]['sub_articles'] = None\n",
    "                \n",
    "        return entries\n",
    "\n",
    "    def __parse_feed(self, feed_url, proxies=None):\n",
    "        if proxies:\n",
    "            r = requests.get(feed_url, proxies = proxies)\n",
    "        else:\n",
    "            r = requests.get(feed_url)\n",
    "\n",
    "        r = requests.get(feed_url)\n",
    "\n",
    "        if 'https://news.google.com/rss/unsupported' in r.url:\n",
    "            raise Exception('This feed is not available')\n",
    "\n",
    "        d = feedparser.parse(r.text)\n",
    "\n",
    "        if not proxies and len(d['entries']) == 0:\n",
    "            d = feedparser.parse(feed_url)\n",
    "\n",
    "        return dict((k, d[k]) for k in ('feed', 'entries'))\n",
    "\n",
    "    def __search_helper(self, query):\n",
    "        return urllib.parse.quote_plus(query)\n",
    "\n",
    "    def __from_to_helper(self, validate=None):\n",
    "        try:\n",
    "            validate = parse_date(validate).strftime('%Y-%m-%d')\n",
    "            return str(validate)\n",
    "        except:\n",
    "            raise Exception('Could not parse your date')\n",
    "            \n",
    "    def __extract_summary(self, text:str):\n",
    "        result = list()\n",
    "        length = len(text.split('target=\"_blank\">'))\n",
    "\n",
    "        if length > 2:\n",
    "            for i in text.split('target=\"_blank\">')[:-1]:\n",
    "                if '</a>' not in i: \n",
    "                    continue\n",
    "                else:\n",
    "                    text = i.split('</a>')[0]\n",
    "                    result.append(text)\n",
    "            result = '. '.join(result)\n",
    "        else:\n",
    "            if '</a>' in text: \n",
    "                text = text.split('target=\"_blank\">')[1]\n",
    "                text = text.split('</a>')[0]\n",
    "                result.append(text)\n",
    "\n",
    "        return result \n",
    "    \n",
    "    def __clean_news(self, r, n: int, show: bool):\n",
    "        r = copy.copy(r)\n",
    "        required, present = 0, len(r.get('entries'))\n",
    "        \n",
    "        if n < present:\n",
    "            required = copy.copy(n)\n",
    "        if n > present:\n",
    "            required = copy.copy(present)\n",
    "\n",
    "        titles, publishers, published_times, summaries, links = [], [], [], [], []\n",
    "\n",
    "        i = 0\n",
    "        for i in range(required):\n",
    "            if r.get('entries')[i].get('title').count('-') > 1:\n",
    "                title = r.get('entries')[i].get('title').rsplit('-', 1)[0]\n",
    "                publisher = r.get('entries')[i].get('title').rsplit('-', 1)[-1].strip()\n",
    "            else:\n",
    "                title = r.get('entries')[i].get('title').split('-')[0]\n",
    "                publisher = r.get('entries')[i].get('title').split('-')[-1].strip()\n",
    "            published_time = r.get('entries')[i].get('published')\n",
    "            raw_summary = r.get('entries')[i].get('summary')\n",
    "            summary = self.__extract_summary(raw_summary)\n",
    "            link = r.get('entries')[i].get('link')\n",
    "\n",
    "            titles.append(title)\n",
    "            publishers.append(publisher)\n",
    "            published_times.append(published_time)\n",
    "            summaries.append(summary)\n",
    "            links.append(link)\n",
    "\n",
    "            if show:\n",
    "                print('Title: ', title)\n",
    "                print('Publisher: ', publisher)\n",
    "                print('Published Time: ', published_time)\n",
    "                print('Summary: ', summary)\n",
    "                print('Link: ', link)\n",
    "                print('\\n')\n",
    "\n",
    "        return {'titles': titles, \n",
    "                'publishers': publishers, \n",
    "                'published_times': published_times, \n",
    "                'summaries': summaries,\n",
    "                'links': links}\n",
    "        \n",
    "    def get_news(self, nums: int, show: bool, proxies=None):\n",
    "        \"\"\"\n",
    "            :param int nums: number of news to retrieve\n",
    "            :param bool show: print searched results\n",
    "            :return dict d: dictionary of curated results\n",
    "            \n",
    "        \"\"\"\n",
    "        d = self.__parse_feed(self.BASE_URL + self.__ceid(), proxies=proxies)\n",
    "        d['entries'] = self.__add_sub_articles(d['entries'])\n",
    "        d = self.__clean_news(d, nums, show)\n",
    "        \n",
    "        return d\n",
    "\n",
    "    def get_news_by_topics(self, topic: str, nums: int, show: bool, proxies=None):\n",
    "        \"\"\"\n",
    "            :param str topic: news topic to query\n",
    "            :param int nums: number of news to retrieve\n",
    "            :param bool show: print searched results\n",
    "            :return dict d: dictionary of curated results\n",
    "            \n",
    "        \"\"\"\n",
    "        if topic.upper() in ['WORLD', 'NATION', 'BUSINESS', 'TECHNOLOGY', 'ENTERTAINMENT', 'SCIENCE', 'SPORTS', 'HEALTH']:\n",
    "            d = self.__parse_feed(self.BASE_URL + '/headlines/section/topic/{}'.format(topic.upper()) + self.__ceid(), \n",
    "                                  proxies = proxies)\n",
    "\n",
    "        else:\n",
    "            d = self.__parse_feed(self.BASE_URL + '/topics/{}'.format(topic) + self.__ceid(), proxies = proxies)\n",
    "\n",
    "        d['entries'] = self.__add_sub_articles(d['entries'])\n",
    "        if len(d['entries']) > 0:\n",
    "            d = self.__clean_news(d, nums, show)\n",
    "            return d\n",
    "        else:\n",
    "            raise Exception('unsupported topic')\n",
    "\n",
    "    def search(self, query: str, nums: int, show: bool, helper=True, when=None, from_=None, to_=None, proxies=None):\n",
    "        \"\"\"\n",
    "            :param str query: news title to query\n",
    "            :param int nums: number of news to retrieve\n",
    "            :param bool show: print searched results\n",
    "            :param str when: results in an article published in last _, example: '30m', '1h', '7d'\n",
    "            :return dict d: dictionary of curated results\n",
    "            \n",
    "        \"\"\"\n",
    "        if when:\n",
    "            query += ' when:' + when\n",
    "\n",
    "        if from_ and not when:\n",
    "            from_ = self.__from_to_helper(validate=from_)\n",
    "            query += ' after:' + from_\n",
    "\n",
    "        if to_ and not when:\n",
    "            to_ = self.__from_to_helper(validate=to_)\n",
    "            query += ' before:' + to_\n",
    "\n",
    "        if helper == True:\n",
    "            query = self.__search_helper(query)\n",
    "\n",
    "        search_ceid = self.__ceid()\n",
    "        search_ceid = search_ceid.replace('?', '&')\n",
    "\n",
    "        d = self.__parse_feed(self.BASE_URL + '/search?q={}'.format(query) + search_ceid, proxies = proxies)\n",
    "        d['entries'] = self.__add_sub_articles(d['entries'])\n",
    "        d = self.__clean_news(d, nums, show)\n",
    "        \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b98bb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6550,
     "status": "ok",
     "timestamp": 1640182214093,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "62c22b8e",
    "outputId": "ea66fe51-cca7-4945-c82e-92feedc9e865"
   },
   "outputs": [],
   "source": [
    "scraper = Scraper(country='MY')\n",
    "news = scraper.get_news(nums=20, show=True)\n",
    "news_topics = scraper.get_news_by_topics(topic='science', nums=20, show=True)\n",
    "news_searched = scraper.search(query='5G', nums=20, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d432dd80",
   "metadata": {
    "id": "1ea966c9"
   },
   "source": [
    "### Levenshtein Distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754aa700",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1640182214093,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "cbfdf705"
   },
   "outputs": [],
   "source": [
    "def levenshtein_dis(seq1, seq2):\n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "                \n",
    "    # print (matrix)\n",
    "    return (matrix[size_x - 1, size_y - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f4d250",
   "metadata": {
    "id": "cf286eac"
   },
   "source": [
    "### Cosine Similarity and TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a2bd8",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1640182215499,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "0c7d08a3"
   },
   "outputs": [],
   "source": [
    "def cosimilarity_tfidf(text1, text2):\n",
    "    \n",
    "    text_list = list([text1, text2])\n",
    "    \n",
    "    vectorizer = feature_extraction.text.TfidfVectorizer()\n",
    "    textX = vectorizer.fit_transform(text_list)\n",
    "    \n",
    "    return metrics.pairwise.cosine_similarity( textX[0], textX[1] ).flatten()[0]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e651d23",
   "metadata": {
    "id": "7db1d469"
   },
   "source": [
    "### News Similarity from Single Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f1cae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 950,
     "output_embedded_package_id": "1p6rK9znB2WT0q84kC8-fWNAIX4BvLTny"
    },
    "executionInfo": {
     "elapsed": 9663,
     "status": "ok",
     "timestamp": 1640182226505,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "9809f652",
    "outputId": "342c4bc9-9cea-4f6f-92f8-5067a6d82175"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def single_news_network(country: str, search_keywords: str, nums: int, when: str, formula: int):\n",
    "    scraper = Scraper(country=country)\n",
    "    searched_news = scraper.search(query=search_keywords, nums=nums, show=False, when=when)\n",
    "    titles_list = searched_news.get('titles')\n",
    "    \n",
    "    sources_distances = list()\n",
    "    sources_distances_df = pd.DataFrame(index=titles_list)\n",
    "\n",
    "    if formula == 1:\n",
    "        for i in range(len(titles_list)):\n",
    "            for j in range(len(titles_list)):\n",
    "                sources_distances.append(cosimilarity_tfidf(titles_list[i], titles_list[j]))\n",
    "    elif formula == 2:\n",
    "        for i in range(len(titles_list)):\n",
    "            for j in range(len(titles_list)):\n",
    "                sources_distances.append(levenshtein_dis(titles_list[i], titles_list[j]))\n",
    "\n",
    "    chunks = [sources_distances[i:i+len(titles_list)] for i in range(0, len(sources_distances), len(titles_list))]\n",
    "\n",
    "    for i, t in enumerate(titles_list):\n",
    "        sources_distances_df[t] = chunks[i]\n",
    "\n",
    "    stacked_df = sources_distances_df.stack().reset_index()\n",
    "    stacked_df.columns = ['Source_1', 'Source_2', 'Distances']\n",
    "\n",
    "    filtered_stacked_df = stacked_df.loc[ (stacked_df['Distances'] > 0) & (stacked_df['Source_1'] != stacked_df['Source_2']) ]\n",
    "\n",
    "    G = nx.from_pandas_edgelist(filtered_stacked_df, source='Source_1', target='Source_2')\n",
    "\n",
    "    plt.figure(figsize=(100,50), dpi=50)\n",
    "    plt.title('News Similarity under the same keywords: {}'.format(search_keywords), fontsize=75)\n",
    "    nx.draw(G, \n",
    "            with_labels=True, \n",
    "            node_color='orange', \n",
    "            node_size=400, \n",
    "            edge_color='grey', \n",
    "            style='dashed', \n",
    "            linewidths=1, \n",
    "            font_size=30)\n",
    "\n",
    "single_news_network(country='MY', \n",
    "                    search_keywords='blockchain', \n",
    "                    nums=20,\n",
    "                    when='12h',\n",
    "                    formula=2) # 1 for lev_dis, 2 for cosine_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953cc30b",
   "metadata": {
    "id": "46889278"
   },
   "source": [
    "### News Similarity from Multi Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b7c411",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1r59KhRUkx2fmsRNz9zZZEiDTDb-PrZPN"
    },
    "executionInfo": {
     "elapsed": 19970,
     "status": "ok",
     "timestamp": 1640182247868,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "3a28ef96",
    "outputId": "40268699-531b-487e-ce28-0747c9207f3c"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def multi_news_networks(country: list, search_keywords: str, nums: int, when: str):\n",
    "    scraper_list, titles_list_of_list, titles_list = ([] for i in range(3))\n",
    "    \n",
    "    for c in country:\n",
    "        scraper_list.append(Scraper(country=c))\n",
    "        \n",
    "    for i in range(len(country)):\n",
    "        searched_news = scraper_list[i].search(query=search_keywords, nums=nums, show=False, when=when)\n",
    "        titles = searched_news.get('titles')\n",
    "        titles_list_of_list.append(titles)\n",
    "    \n",
    "    titles_df = pd.DataFrame(data=titles_list_of_list).T\n",
    "    titles_df.columns = country.copy()\n",
    "    titles_df = pd.melt(titles_df, value_vars=country)\n",
    "    titles_df.rename(columns={'variable': 'country', 'value': 'title'}, inplace=True)\n",
    "    \n",
    "    titles_list = [t for sublist in titles_list_of_list for t in sublist] # list of list to list\n",
    "    titles_list = list(set(titles_list)) # remove duplicates title\n",
    "\n",
    "    node_characteristic = pd.DataFrame({'ID': country + titles_list,\n",
    "                                        'type': country + ['t'] * len(titles_list)})\n",
    "    \n",
    "    plt.figure(figsize=(50, 50), dpi=150)\n",
    "    plt.title('Multicountry News Similarity: The significant', fontsize=50)\n",
    "    \n",
    "    G = nx.from_pandas_edgelist(titles_df, source='country', target='title', create_using=nx.Graph())\n",
    "        \n",
    "    node_characteristic = node_characteristic.set_index('ID')\n",
    "    node_characteristic = node_characteristic.reindex(G.nodes())\n",
    "    node_characteristic['type'] = pd.Categorical(node_characteristic['type'])\n",
    "\n",
    "    cmap = matplotlib.colors.ListedColormap(['yellow', 'C0', 'green', 'red', 'darkorange', 'thistle'])\n",
    "    \n",
    "    node_sizes = [4000 if entry != 't' else 300 for entry in node_characteristic.type]\n",
    "    \n",
    "    nx.draw(G, \n",
    "            with_labels=True,\n",
    "            node_size=node_sizes, \n",
    "            node_color=node_characteristic['type'].cat.codes,\n",
    "            cmap=cmap,\n",
    "            edge_color='grey', \n",
    "            style='dashed', \n",
    "            linewidths=1, \n",
    "            font_size=20)\n",
    "    \n",
    "multi_news_networks(country=['MY', 'US', 'GB', 'SG', 'IN'], search_keywords='blockchain', nums=20, when='12h')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc2e5fc",
   "metadata": {
    "id": "0bc40c4b"
   },
   "source": [
    "### Train Sentiment LSTM Model for News "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92172a8c",
   "metadata": {
    "executionInfo": {
     "elapsed": 983,
     "status": "ok",
     "timestamp": 1640182255804,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "3089c74a"
   },
   "outputs": [],
   "source": [
    "def read_sentiment_data():\n",
    "    # any sentiment dataset will do\n",
    "    sentiment_data = pd.read_csv(current_directory + 'datasets/sentiment.csv', header=None, encoding='ISO-8859-1')\n",
    "    sentiment_data.columns = ['sentiment', 'text']\n",
    "    return sentiment_data\n",
    "\n",
    "sentiment_data = read_sentiment_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca20b6a",
   "metadata": {
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1640182259780,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "1c6dc2f0"
   },
   "outputs": [],
   "source": [
    "def clean_the_text(text: str):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    text = re.sub(r'http\\S+', r'<URL>', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    stop_words = set(corpus.stopwords.words('english'))\n",
    "    word_token = tokenize.word_tokenize(text)\n",
    "    word_token = [w for w in word_token if w not in stop_words]\n",
    "    \n",
    "    return ' '.join(word_token)\n",
    "\n",
    "MAX_WORDS = 5000\n",
    "MAX_LEN = 50\n",
    "\n",
    "def tokenize_pad_sequences(text: str):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_WORDS, lower=True, split=' ')\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    X = tokenizer.texts_to_sequences(text)\n",
    "    X = tf.keras.preprocessing.sequence.pad_sequences(X, padding='post', maxlen=MAX_LEN)\n",
    "    return X, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceadea3b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 78651,
     "status": "ok",
     "timestamp": 1640182340854,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "1314528a",
    "outputId": "52ae409b-bb33-4ad3-d0b3-541b0aed3ce1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def sentiment_lstm_model(data, plot=True):\n",
    "    sentiment_data = data.copy()\n",
    "    \n",
    "    sentiment_data['text'] = sentiment_data['text'].apply(lambda x: clean_the_text(x))\n",
    "    X, tokenizer = tokenize_pad_sequences(text=sentiment_data['text'])\n",
    "    y = pd.get_dummies(sentiment_data['sentiment'])\n",
    "    trainX, testX, trainy, testy = model_selection.train_test_split(X, y, test_size=.1, shuffle=True, random_state=0)\n",
    "    \n",
    "    VOCAB_SIZE = 5000\n",
    "    EMBEDDING_SIZE = 32\n",
    "    EPOCHS = 50\n",
    "    BATCH_SIZE = 64\n",
    "    CALLBACK = tf.keras.callbacks.EarlyStopping(monitor='val_acc', \n",
    "                                                patience=15, \n",
    "                                                min_delta=0.01, \n",
    "                                                restore_best_weights=True)\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_SIZE, input_length=MAX_LEN))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)))\n",
    "    model.add(tf.keras.layers.Dropout(.4))\n",
    "    model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(trainX, trainy, \n",
    "                        validation_data=(testX, testy), \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        epochs=EPOCHS, \n",
    "                        verbose=1,\n",
    "                        callbacks=[CALLBACK])\n",
    "    \n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10,5), dpi=100)\n",
    "        ax[0].plot(history.history['acc'], marker='o', label='Accuracy')\n",
    "        ax[0].plot(history.history['val_acc'], marker='v', label='Validation Accuracy')\n",
    "        ax[0].set_title('Accuracies')\n",
    "        ax[0].set_xlabel('Epochs')\n",
    "        ax[0].set_ylabel('Accuracy')\n",
    "        ax[0].legend()\n",
    "        \n",
    "        ax[1].plot(history.history['loss'], marker='o', label='Loss')\n",
    "        ax[1].plot(history.history['val_loss'], marker='v', label='Validation Loss')\n",
    "        ax[1].set_title('Losses')\n",
    "        ax[1].set_xlabel('Epochs')\n",
    "        ax[1].set_ylabel('Loss')\n",
    "        ax[1].legend()\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    return model, tokenizer\n",
    "\n",
    "slstm, tokenizer = sentiment_lstm_model(data=sentiment_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f204b19",
   "metadata": {
    "id": "fb88fc6b"
   },
   "source": [
    "### Predict News Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c3fb1d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1501,
     "status": "ok",
     "timestamp": 1640182343659,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "675d386a",
    "outputId": "a63ec352-a5fa-4658-a501-00a88f6b7c59"
   },
   "outputs": [],
   "source": [
    "def sentiment_predict(text, model, tokenizer):\n",
    "    text = copy.copy(text)\n",
    "    # text = clean_the_text(text)\n",
    "    sentiment_state = ['Negative', 'Neutral', 'Positive']\n",
    "    MAX_LEN = 50\n",
    "    textX = tokenizer.texts_to_sequences(text)\n",
    "    textX = tf.keras.preprocessing.sequence.pad_sequences(textX, padding='post', maxlen=MAX_LEN)\n",
    "    texty = slstm.predict(textX).argmax(axis=1)\n",
    "    print('Sentiment State: ', sentiment_state[texty[0]])\n",
    "    \n",
    "sentiment_predict(text=['this is a testing sentences'], model=slstm, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32c393",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1640182343661,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "1f00a0cc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_news_sentiment(topic: str, nums: int, model, tokenizer):\n",
    "    topic = copy.copy(topic)\n",
    "    nums = copy.copy(nums)\n",
    "    \n",
    "    scraper = Scraper(country='MY')\n",
    "    news_topics = scraper.get_news_by_topics(topic=topic, nums=nums, show=False)\n",
    "    \n",
    "    for title in news_topics.get('titles'):\n",
    "        sentiment_predict(text=[title], model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800260d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1966,
     "status": "ok",
     "timestamp": 1640182345615,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "4d2106f1",
    "outputId": "b215417b-497d-4429-b0f0-301657ae70cf"
   },
   "outputs": [],
   "source": [
    "check_news_sentiment(topic='business', nums=10, model=slstm, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a763a5",
   "metadata": {
    "id": "1a3be7ae"
   },
   "source": [
    "### News Keywords Extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24fd4b2",
   "metadata": {
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1640182351382,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "9765e585"
   },
   "outputs": [],
   "source": [
    "def get_news_keywords(country: str, query: str, nums: int): \n",
    "    scraper = Scraper(country=country)\n",
    "    news_searched = scraper.search(query=query, nums=nums, show=False)\n",
    "    \n",
    "    spacy_nlp = spacy.load('en_core_web_sm')\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN'] \n",
    "    \n",
    "    titles_core = list()\n",
    "    \n",
    "    for title in news_searched.get('titles'):\n",
    "        doc = spacy_nlp(title.lower())\n",
    "        core = list()\n",
    "        for token in doc:\n",
    "            if(token.text in spacy_nlp.Defaults.stop_words or token.text in punctuation):\n",
    "                continue\n",
    "                \n",
    "            if(token.pos_ in pos_tag):\n",
    "                core.append(token.text)\n",
    "        \n",
    "        titles_core.append(' '.join(core))\n",
    "            \n",
    "    return titles_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f6fc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8497,
     "status": "ok",
     "timestamp": 1640182601178,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "a96b5cd7",
    "outputId": "fac1c0ac-1a73-4888-f5f6-47f453f177f3"
   },
   "outputs": [],
   "source": [
    "get_news_keywords(country='MY', query='blockchain', nums=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48faa58e",
   "metadata": {
    "id": "113175dc"
   },
   "source": [
    "### Clustering News from Various Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca606f24",
   "metadata": {
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1640182606431,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "6a734f87"
   },
   "outputs": [],
   "source": [
    "news_from_country = ['MY', 'US', 'GB', 'IN', 'CN', 'DE', 'FR', 'TW', 'HK', 'AU', 'KR', 'JP', \n",
    "                    'CA', 'SG', 'ID', 'NZ', 'IE', 'IL', 'PK', 'ZA', 'CH', 'IT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a253c2",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1640182607995,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "4d8bfafd"
   },
   "outputs": [],
   "source": [
    "def clean_detect_translate(text: str, source_language: str=None, trg_language: str=None):    \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    if source_language == None: \n",
    "        source_language = detect(text)\n",
    "        lang_dict = {'en': 'en', 'zh-cn': 'zh-CN', 'zh-tw': 'zh-TW', 'de': 'de', 'fr': 'fr', 'ko': 'ko', 'ja': 'ja', 'id': 'id'}\n",
    "        source_language = lang_dict.get(source_language)\n",
    "        \n",
    "        if source_language == None:\n",
    "            return None\n",
    "        \n",
    "    if source_language == trg_language:\n",
    "        return text\n",
    "    else:\n",
    "        # print('Translating news')\n",
    "        translator = GoogleTranslator(source=source_language, target=trg_language)\n",
    "        translated_text = translator.translate(text)\n",
    "        # GoogleTranslator.get_supported_languages(as_dict=True)\n",
    "        translated_text = translator.translate(text)\n",
    "    \n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76968361",
   "metadata": {
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1640182610528,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "9c0219c2"
   },
   "outputs": [],
   "source": [
    "def detect_cjk(text: str):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', str(text))\n",
    "    if re.search(\"[\\u4e00-\\u9FFF]\", text):\n",
    "        return False\n",
    "    if re.search(\"[\\uac00-\\ud7a3]\", text):\n",
    "        return False\n",
    "    if re.search(\"[\\u3040-\\u30ff]\", text):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03814230",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "34a17712953640e89726aff5383fab09",
      "245faeabbcd0484a93ef769ecfec2830",
      "5876a54ce1924d6aa413023eeb5eb91c",
      "a79bf5c405414ac19159b201a97ad272",
      "80d391f74581471292c34eff3d0a4321",
      "89772f9a416240de8e296173a9749ec3",
      "c759fb0f256444cd943c26deac4875e1",
      "984abe0e65e346a5b7eb01c1f21410fd"
     ]
    },
    "executionInfo": {
     "elapsed": 356393,
     "status": "ok",
     "timestamp": 1640182968441,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "0b91df6e",
    "outputId": "56c2a855-af59-448b-f774-bdf129abd464",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def preprocessing_news(country_list: list):\n",
    "    news_dict = dict()\n",
    "    \n",
    "    for c in log_progress(country_list, every=1):\n",
    "        extracted_news = list()\n",
    "        country_lang_dict = {'MY': 'en', \n",
    "                             'US': 'en', \n",
    "                             'GB': 'en', \n",
    "                             'IN': 'en', \n",
    "                             'CN': 'CN', \n",
    "                             'DE': 'de',\n",
    "                             'FR': 'fr', \n",
    "                             'TW': 'TW',\n",
    "                             'HK': 'TW',\n",
    "                             'AU': 'en',\n",
    "                             'KR': 'ko',\n",
    "                             'JP': 'ja',\n",
    "                             'CA': 'en',\n",
    "                             'SG': 'en',\n",
    "                             'ID': 'en',\n",
    "                             'NZ': 'en',\n",
    "                             'IE': 'en',\n",
    "                             'IL': 'en',\n",
    "                             'PK': 'en',\n",
    "                             'ZA': 'en',\n",
    "                             'CH': 'de',\n",
    "                             'IT': 'it',}\n",
    "        \n",
    "        language_use = country_lang_dict.get(c)\n",
    "        scraper = Scraper(language=language_use, country=c)\n",
    "        news = scraper.get_news_by_topics(topic='world', nums=50, show=False)\n",
    "        \n",
    "        lang = 'zh-TW' if c == 'HK' or c == 'TW' else ('zh-CN' if c == 'CN' else None) \n",
    "        if lang == None:\n",
    "            lang = country_lang_dict.get(c)\n",
    "         \n",
    "        for i in range(len(news.get('titles'))):\n",
    "            cleaned_text = clean_detect_translate(news.get('titles')[i], source_language=lang, trg_language='en')\n",
    "            if detect_cjk(text=cleaned_text):\n",
    "                extracted_news.append(cleaned_text)\n",
    "\n",
    "        print('Successfully scrape {} news'.format(c)) if len(extracted_news) > 0 else print('Failed to scrape {} news'.format(c))\n",
    "        news_dict[c] = extracted_news\n",
    "        print(c)\n",
    "        print(extracted_news)\n",
    "        print('\\n')\n",
    "        \n",
    "    compiled_news = pd.DataFrame()\n",
    "    for c in country_list:\n",
    "        compiled_news = pd.concat([compiled_news, pd.DataFrame({c: news_dict.get(c)})], axis=1)\n",
    "        \n",
    "    return compiled_news\n",
    "        \n",
    "news_data = preprocessing_news(country_list=news_from_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dbc6da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3579,
     "status": "ok",
     "timestamp": 1640183073055,
     "user": {
      "displayName": "Wei Jie Lee Kiong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11519924154603132072"
     },
     "user_tz": -480
    },
    "id": "a7d21af2",
    "outputId": "1ebc1941-d88a-4c6e-fe3b-adfb5ab8d24d"
   },
   "outputs": [],
   "source": [
    "def news_kmeans_clustering():\n",
    "    melted_news_data = pd.melt(news_data, value_vars=news_from_country)\n",
    "    melted_news_data.rename(columns={'variable': 'Country', 'value': 'News'}, inplace=True)\n",
    "    melted_news_data.dropna(inplace=True)\n",
    "    # le = preprocessing.LabelEncoder()\n",
    "    # melted_news_data['Encoder Country'] = preprocessing.LabelEncoder().fit_transform(melted_news_data['Country'])\n",
    "\n",
    "    vectorizer = feature_extraction.text.TfidfVectorizer(stop_words='english')\n",
    "    textX = vectorizer.fit_transform(melted_news_data['News'].values)\n",
    "    # print('n_features: {}, vocab: {}'.format(textX.shape[0], textX.shape[1]))\n",
    "\n",
    "    # # Elbow Method\n",
    "    # sse = {}\n",
    "    # for k in range(1, 11):\n",
    "    #     km = cluster.KMeans(n_clusters=k, random_state=0).fit(textX)\n",
    "    #     sse[k] = km.inertia_\n",
    "\n",
    "    # plt.figure(figsize=(10,5), dpi=100)\n",
    "    # plt.plot(list(sse.keys()), list(sse.values()))\n",
    "    # plt.title('Elbow Method for Optimal K')\n",
    "    # plt.xlabel('Nums of K')\n",
    "    # plt.ylabel('Inertia')\n",
    "    # plt.show()\n",
    "\n",
    "    km = cluster.KMeans(n_clusters=5, random_state=0).fit(textX)\n",
    "    melted_news_data['Cluster'] = km.labels_\n",
    "\n",
    "    country_list = melted_news_data['Country'].unique().tolist()\n",
    "    news_list = melted_news_data['News'].unique().tolist()\n",
    "\n",
    "    G = nx.from_pandas_edgelist(melted_news_data, source='Cluster', target='Country', create_using=nx.Graph())\n",
    "    \n",
    "    node_characteristic = pd.DataFrame({'ID': country_list + news_list,\n",
    "                                        'type': ['c'] * len(country_list) + ['n'] * len(news_list)})\n",
    "    node_characteristic = node_characteristic.set_index('ID')\n",
    "    node_characteristic = node_characteristic.reindex(G.nodes())\n",
    "    node_characteristic['type'] = pd.Categorical(node_characteristic['type'])\n",
    "    cmap = matplotlib.colors.ListedColormap(['blue', 'red'])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(30,30), dpi=100)\n",
    "    ax.set_title('Countries-News KMeans Clustering', fontsize=30)\n",
    "    nx.draw(G, \n",
    "            with_labels=True,\n",
    "            node_size=4000, \n",
    "            node_color=node_characteristic['type'].cat.codes,\n",
    "            cmap=cmap,\n",
    "            edge_color='grey', \n",
    "            style='dashed', \n",
    "            linewidths=1, \n",
    "            font_size=40,\n",
    "            font_color='white')\n",
    "\n",
    "    legend_elements = [mpl.lines.Line2D([0], [0], marker='o', color='w', label='Country', markerfacecolor='red', markersize=30),\n",
    "                       mpl.lines.Line2D([0], [0], marker='o', color='w', label='Cluster', markerfacecolor='blue', markersize=30)]\n",
    "    \n",
    "    ax.legend(handles=legend_elements, loc='best', fontsize='xx-large', labelspacing=1.5, borderpad=1.5)\n",
    "    \n",
    "    # overall = nx.degree_centrality(G)\n",
    "    # print([overall[k] for k in news_from_country if k in overall])\n",
    "\n",
    "news_kmeans_clustering()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "245faeabbcd0484a93ef769ecfec2830": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34a17712953640e89726aff5383fab09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5876a54ce1924d6aa413023eeb5eb91c",
       "IPY_MODEL_a79bf5c405414ac19159b201a97ad272"
      ],
      "layout": "IPY_MODEL_245faeabbcd0484a93ef769ecfec2830"
     }
    },
    "5876a54ce1924d6aa413023eeb5eb91c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89772f9a416240de8e296173a9749ec3",
      "placeholder": "",
      "style": "IPY_MODEL_80d391f74581471292c34eff3d0a4321",
      "value": "Items: 22"
     }
    },
    "80d391f74581471292c34eff3d0a4321": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89772f9a416240de8e296173a9749ec3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "984abe0e65e346a5b7eb01c1f21410fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a79bf5c405414ac19159b201a97ad272": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_984abe0e65e346a5b7eb01c1f21410fd",
      "max": 22,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c759fb0f256444cd943c26deac4875e1",
      "value": 22
     }
    },
    "c759fb0f256444cd943c26deac4875e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
